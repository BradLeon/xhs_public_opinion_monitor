import os
import logging
from datetime import datetime
from typing import List, Dict, Any

from src.xhs_public_opinion.core.config import Settings
from src.xhs_public_opinion.database.supabase_db import SupabaseDatabase
from src.xhs_public_opinion.tools.multimodal_analyzer_tool import MultimodalAnalyzerTool
from src.xhs_public_opinion.tools.data_merger_tool import DataMergerTool
from src.xhs_public_opinion.tools.sov_calculator_tool import SOVCalculatorTool
from src.xhs_public_opinion.tools.brand_sentiment_extractor_tool import BrandSentimentExtractorTool
from src.xhs_public_opinion.tools.specific_notes_reader_tool import SpecificNotesReaderTool
from src.xhs_public_opinion.tools.sov_visualization_tool import SOVVisualizationTool

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def main():
    """ä¸»å‡½æ•°"""
    print("\nğŸš€ å°çº¢ä¹¦èˆ†æƒ…ç›‘æ§ç³»ç»Ÿ")
    print("=" * 50)
    
    while True:
        print("\nğŸ“‹ è¯·é€‰æ‹©æ“ä½œ:")
        print("1. ğŸ” é‡‡é›†ç¬”è®°æ•°æ®")
        print("2. ğŸ¤– å¤šæ¨¡æ€åˆ†æ")
        print("3. ğŸ”„ æ•°æ®åˆå¹¶æ’åº")
        print("4. ğŸ“Š SOVç»Ÿè®¡åˆ†æ")
        print("5. ğŸ’­ å“ç‰Œæƒ…æ„Ÿåˆ†æ") 
        print("6. âš¡ ä¸€é”®è¿è¡Œå®Œæ•´æµç¨‹")
        print("7. ğŸ“ˆ ç”ŸæˆSOVå•æ¡£ä½å›¾è¡¨")
        print("8. ğŸ“‹ ç”ŸæˆSOVç»¼åˆæŠ¥å‘Š")
        print("0. ğŸšª é€€å‡ºç³»ç»Ÿ")
        
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (0-8): ").strip()
        
        if choice == "0":
            print("\nğŸ‘‹ è°¢è°¢ä½¿ç”¨ï¼Œå†è§!")
            break
        elif choice == "1":
            run_data_collection()
        elif choice == "2":
            run_multimodal_analysis()
        elif choice == "3":
            run_data_merger()
        elif choice == "4":
            run_sov_analysis()
        elif choice == "5":
            run_brand_sentiment()
        elif choice == "6":
            run_complete_pipeline()
        elif choice == "7":
            run_sov_visualization()
        elif choice == "8":
            run_comprehensive_report()
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

def run_data_collection():
    """è¿è¡Œæ•°æ®é‡‡é›†"""
    print("\nğŸ” æ•°æ®é‡‡é›†åŠŸèƒ½")
    print("-" * 30)
    print("è¯¥åŠŸèƒ½éœ€è¦é…åˆçˆ¬è™«å·¥å…·ä½¿ç”¨ï¼Œè¯·ç¡®ä¿å·²ç»å°†æ•°æ®å¯¼å…¥åˆ°æ•°æ®åº“ä¸­")

def run_multimodal_analysis():
    """è¿è¡Œå¤šæ¨¡æ€åˆ†æ"""
    print("\nğŸ¤– å¤šæ¨¡æ€åˆ†æ")
    print("-" * 30)
    
    keywords = input("è¯·è¾“å…¥å…³é”®è¯ (å¤šä¸ªå…³é”®è¯ç”¨é€—å·åˆ†éš”): ").strip()
    if not keywords:
        print("âŒ å…³é”®è¯ä¸èƒ½ä¸ºç©º")
        return
    
    keyword_list = [k.strip() for k in keywords.split(",")]
    
    for keyword in keyword_list:
        print(f"\nåˆ†æå…³é”®è¯: {keyword}")
        try:
            # 1. æ•°æ®åˆå¹¶æ’åºï¼Œè·å–å‰100å
            merger_tool = DataMergerTool()
            merge_result = merger_tool._run(keyword=keyword)
            print(f"æ•°æ®åˆå¹¶ç»“æœ: {merge_result}")
            
            # 2. è·å–å‰100ånote_id
            top_note_ids = _get_top_note_ids_from_csv(keyword)
            if not top_note_ids:
                print(f"âŒ æœªæ‰¾åˆ°å…³é”®è¯ {keyword} çš„æ’åºæ•°æ®")
                continue
            
            # 3. åªå¯¹å‰100åè¿›è¡Œå¤šæ¨¡æ€åˆ†æ
            _analyze_top_notes(keyword, top_note_ids)
            
            # 4. SOVç»Ÿè®¡
            sov_tool = SOVCalculatorTool()
            sov_result = sov_tool._run(keyword=keyword)
            print(f"SOVç»Ÿè®¡ç»“æœ: {sov_result}")
            
            # 5. å“ç‰Œæƒ…æ„Ÿåˆ†æ
            sentiment_tool = BrandSentimentExtractorTool()
            sentiment_result = sentiment_tool._run(keyword=keyword)
            print(f"æƒ…æ„Ÿåˆ†æç»“æœ: {sentiment_result}")
            
        except Exception as e:
            print(f"âŒ å…³é”®è¯ {keyword} å¤„ç†å¤±è´¥: {e}")

def run_data_merger():
    """è¿è¡Œæ•°æ®åˆå¹¶"""
    print("\nğŸ”„ æ•°æ®åˆå¹¶æ’åº")
    print("-" * 30)
    
    keyword = input("è¯·è¾“å…¥å…³é”®è¯: ").strip()
    if not keyword:
        print("âŒ å…³é”®è¯ä¸èƒ½ä¸ºç©º")
        return
    
    try:
        tool = DataMergerTool()
        result = tool._run(keyword=keyword)
        print(f"\n{result}")
        
    except Exception as e:
        print(f"âŒ æ•°æ®åˆå¹¶å¤±è´¥: {e}")

def run_sov_analysis():
    """è¿è¡ŒSOVåˆ†æ"""
    print("\nğŸ“Š SOVç»Ÿè®¡åˆ†æ")
    print("-" * 30)
    
    keyword = input("è¯·è¾“å…¥å…³é”®è¯: ").strip()
    if not keyword:
        print("âŒ å…³é”®è¯ä¸èƒ½ä¸ºç©º")
        return
    
    try:
        tool = SOVCalculatorTool()
        result = tool._run(keyword=keyword)
        print(f"\n{result}")
        
    except Exception as e:
        print(f"âŒ SOVåˆ†æå¤±è´¥: {e}")

def run_brand_sentiment():
    """è¿è¡Œå“ç‰Œæƒ…æ„Ÿåˆ†æ"""
    print("\nğŸ’­ å“ç‰Œæƒ…æ„Ÿåˆ†æ")
    print("-" * 30)
    
    keyword = input("è¯·è¾“å…¥å…³é”®è¯: ").strip()
    if not keyword:
        print("âŒ å…³é”®è¯ä¸èƒ½ä¸ºç©º")
        return
    
    try:
        tool = BrandSentimentExtractorTool()
        result = tool._run(keyword=keyword)
        print(f"\n{result}")
        
    except Exception as e:
        print(f"âŒ å“ç‰Œæƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")

def run_complete_pipeline():
    """è¿è¡Œå®Œæ•´æµç¨‹"""
    print("\nâš¡ ä¸€é”®è¿è¡Œå®Œæ•´æµç¨‹")
    print("-" * 30)
    
    # æä¾›å…³é”®è¯é€‰æ‹©
    print("æ”¯æŒçš„å…³é”®è¯:")
    print("1. è„±æ¯›")
    print("2. ä¸°ç›ˆè“¬æ¾æ´—å‘æ°´")
    print("3. ç¼•çµ")
    print("4. livingproof")
    print("5. è‡ªå®šä¹‰å…³é”®è¯")
    print("6. æ‰¹é‡å¤„ç†æ‰€æœ‰å…³é”®è¯")
    
    choice = input("\nè¯·é€‰æ‹© (1-6): ").strip()
    keyword_map = {
        "1": ["è„±æ¯›"],
        "2": ["ä¸°ç›ˆè“¬æ¾æ´—å‘æ°´"],
        "3": ["ç¼•çµ"],
        "4": ["livingproof"],
        "6": ["è„±æ¯›", "ä¸°ç›ˆè“¬æ¾æ´—å‘æ°´", "ç¼•çµ", "livingproof"]
    }
    
    if choice in keyword_map:
        keyword_list = keyword_map[choice]
    elif choice == "5":
        keywords = input("è¯·è¾“å…¥å…³é”®è¯ (å¤šä¸ªå…³é”®è¯ç”¨é€—å·åˆ†éš”): ").strip()
        if not keywords:
            print("âŒ å…³é”®è¯ä¸èƒ½ä¸ºç©º")
            return
        keyword_list = [k.strip() for k in keywords.split(",")]
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")
        return
    
    for keyword in keyword_list:
        print(f"\n{'='*20} å¤„ç†å…³é”®è¯: {keyword} {'='*20}")
        
        try:
            # 1. æ•°æ®åˆå¹¶æ’åº
            print("ğŸ”„ Step 1: æ•°æ®åˆå¹¶æ’åº...")
            merger_tool = DataMergerTool()
            merge_result = merger_tool._run(keyword=keyword)
            print(f"åˆå¹¶ç»“æœ: {merge_result}")
            
            # 2. è·å–å‰100ånote_idè¿›è¡Œåˆ†æ
            print("ğŸ” Step 2: è·å–å‰100åç¬”è®°...")
            top_note_ids = _get_top_note_ids_from_csv(keyword)
            if not top_note_ids:
                print(f"âŒ æœªæ‰¾åˆ°å…³é”®è¯ {keyword} çš„æ’åºæ•°æ®ï¼Œè·³è¿‡")
                continue
            
            # 3. å¤šæ¨¡æ€åˆ†æå‰100å
            print("ğŸ¤– Step 3: å¤šæ¨¡æ€åˆ†æå‰100å...")
            _analyze_top_notes(keyword, top_note_ids)
            
            # 4. SOVç»Ÿè®¡
            print("ğŸ“Š Step 4: SOVç»Ÿè®¡åˆ†æ...")
            sov_tool = SOVCalculatorTool()
            sov_result = sov_tool._run(keyword=keyword)
            print(f"SOVç»“æœ: {sov_result}")
            
            # 5. å“ç‰Œæƒ…æ„Ÿåˆ†æ
            print("ğŸ’­ Step 5: å“ç‰Œæƒ…æ„Ÿåˆ†æ...")
            sentiment_tool = BrandSentimentExtractorTool()
            sentiment_result = sentiment_tool._run(keyword=keyword)
            print(f"æƒ…æ„Ÿç»“æœ: {sentiment_result}")
            
            print(f"âœ… å…³é”®è¯ {keyword} å¤„ç†å®Œæˆ!")
            
        except Exception as e:
            logger.error(f"å…³é”®è¯ {keyword} å¤„ç†å¤±è´¥: {e}")
            print(f"âŒ å…³é”®è¯ {keyword} å¤„ç†å¤±è´¥: {e}")

def run_sov_visualization():
    """è¿è¡ŒSOVå•æ¡£ä½å¯è§†åŒ–"""
    print("\nğŸ“ˆ SOVå•æ¡£ä½å›¾è¡¨ç”Ÿæˆ")
    print("-" * 30)
    
    # æä¾›å…³é”®è¯é€‰æ‹©
    print("æ”¯æŒçš„å…³é”®è¯:")
    print("1. è„±æ¯›ä»ª")
    print("2. ä¸°ç›ˆè“¬æ¾æ´—å‘æ°´")
    print("3. ç¼•çµ")
    print("4. livingproof")
    print("5. è‡ªå®šä¹‰å…³é”®è¯")
    
    choice = input("\nè¯·é€‰æ‹©å…³é”®è¯ (1-5): ").strip()
    keyword_map = {
        "1": "è„±æ¯›ä»ª",
        "2": "ä¸°ç›ˆè“¬æ¾æ´—å‘æ°´", 
        "3": "ç¼•çµ",
        "4": "livingproof"
    }
    
    if choice in keyword_map:
        keyword = keyword_map[choice]
    elif choice == "5":
        keyword = input("è¯·è¾“å…¥è‡ªå®šä¹‰å…³é”®è¯: ").strip()
        if not keyword:
            print("âŒ å…³é”®è¯ä¸èƒ½ä¸ºç©º")
            return
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")
        return
    
    tier = input("è¯·é€‰æ‹©æ¡£ä½ (top20/top50/top100ï¼Œé»˜è®¤ top20): ").strip()
    if not tier:
        tier = "top20"
    
    try:
        tool = SOVVisualizationTool()
        result = tool._run(
            keyword=keyword,
            tier=tier,
            chart_type="single",
            output_dir="outputs"
        )
        print(f"\n{result}")
        
    except Exception as e:
        print(f"âŒ å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")

def run_comprehensive_report():
    """è¿è¡Œç»¼åˆæŠ¥å‘Šç”Ÿæˆ"""
    print("\nğŸ“‹ SOVç»¼åˆæŠ¥å‘Šç”Ÿæˆ")
    print("-" * 30)
    
    # æä¾›å…³é”®è¯é€‰æ‹©
    print("æ”¯æŒçš„å…³é”®è¯:")
    print("1. è„±æ¯›ä»ª")
    print("2. ä¸°ç›ˆè“¬æ¾æ´—å‘æ°´")
    print("3. ç¼•çµ")
    print("4. livingproof")
    print("5. è‡ªå®šä¹‰å…³é”®è¯")
    
    choice = input("\nè¯·é€‰æ‹©å…³é”®è¯ (1-5): ").strip()
    keyword_map = {
        "1": "è„±æ¯›ä»ª",
        "2": "ä¸°ç›ˆè“¬æ¾æ´—å‘æ°´",
        "3": "ç¼•çµ", 
        "4": "livingproof"
    }
    
    if choice in keyword_map:
        keyword = keyword_map[choice]
    elif choice == "5":
        keyword = input("è¯·è¾“å…¥è‡ªå®šä¹‰å…³é”®è¯: ").strip()
        if not keyword:
            print("âŒ å…³é”®è¯ä¸èƒ½ä¸ºç©º")
            return
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")
        return
    
    target_brand = input("è¯·è¾“å…¥ç›®æ ‡å“ç‰Œ (å¯é€‰): ").strip()
    
    try:
        tool = SOVVisualizationTool()
        result = tool._run(
            keyword=keyword,
            chart_type="comprehensive",
            target_brand=target_brand,
            output_dir="outputs"
        )
        print(f"\n{result}")
        
    except Exception as e:
        print(f"âŒ ç»¼åˆæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")

def _get_top_note_ids_from_csv(keyword: str, limit: int = 100) -> List[str]:
    """ä»CSVæ–‡ä»¶ä¸­è·å–å‰Nåçš„note_id"""
    try:
        import pandas as pd
        import glob
        
        # æŸ¥æ‰¾æœ€æ–°çš„åˆå¹¶æ•°æ®æ–‡ä»¶
        pattern = os.path.join("outputs", keyword, "merged_data_*.csv")
        files = glob.glob(pattern)
        
        if not files:
            logger.warning(f"æœªæ‰¾åˆ°å…³é”®è¯ {keyword} çš„åˆå¹¶æ•°æ®æ–‡ä»¶")
            return []
        
        # é€‰æ‹©æœ€æ–°æ–‡ä»¶
        latest_file = max(files, key=os.path.getctime)
        logger.info(f"ä½¿ç”¨æ•°æ®æ–‡ä»¶: {latest_file}")
        
        # è¯»å–æ•°æ®
        df = pd.read_csv(latest_file, encoding='utf-8-sig')
        
        # æŒ‰rankæ’åºï¼Œå–å‰Nå
        df_sorted = df.sort_values('rank').head(limit)
        note_ids = df_sorted['note_id'].tolist()
        
        logger.info(f"è·å–åˆ° {len(note_ids)} ä¸ªnote_id")
        return note_ids
        
    except Exception as e:
        logger.error(f"è·å–note_idå¤±è´¥: {e}")
        return []

def _analyze_top_notes(keyword: str, note_ids: List[str]):
    """å¯¹å‰100åç¬”è®°è¿›è¡Œå¤šæ¨¡æ€åˆ†æ"""
    try:
        # ä½¿ç”¨SpecificNotesReaderToolè¯»å–æŒ‡å®šç¬”è®°
        reader_tool = SpecificNotesReaderTool()
        notes_result = reader_tool._run(note_ids=",".join(note_ids))
        
        if "âœ…" not in notes_result:
            logger.warning(f"è¯»å–ç¬”è®°æ•°æ®å¤±è´¥: {notes_result}")
            return
        
        # ä½¿ç”¨MultimodalAnalyzerToolè¿›è¡Œåˆ†æ
        analyzer_tool = MultimodalAnalyzerTool()
        analysis_result = analyzer_tool._run(keyword=keyword)
        
        logger.info(f"å¤šæ¨¡æ€åˆ†æç»“æœ: {analysis_result}")
        
    except Exception as e:
        logger.error(f"åˆ†æå‰100åç¬”è®°å¤±è´¥: {e}")

if __name__ == "__main__":
    main() 