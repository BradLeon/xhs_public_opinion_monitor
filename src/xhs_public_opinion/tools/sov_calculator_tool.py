import os
import json
import pandas as pd
import numpy as np
from typing import List, Dict, Any, Optional, Tuple
from crewai.tools import BaseTool
from supabase import create_client, Client
import logging
from datetime import datetime
import glob

# å¯¼å…¥å“ç‰Œæ ‡å‡†åŒ–å·¥å…·
from .brand_normalizer import get_brand_normalizer

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SOVCalculatorTool(BaseTool):
    """SOVè®¡ç®—å·¥å…· - è®¡ç®—å„å“ç‰Œåœ¨å…³é”®è¯ä¸‹çš„å£°é‡å æ¯”ï¼ˆShare of Voiceï¼‰"""
    name: str = "sov_calculator"
    description: str = "åŸºäºåˆå¹¶åçš„CSVæ•°æ®ï¼Œè®¡ç®—å„å“ç‰Œåœ¨æŒ‡å®šå…³é”®è¯ä¸‹çš„SOVï¼ˆå£°é‡å æ¯”ï¼‰ï¼Œæ”¯æŒåˆ†æ¡£ä½è®¡ç®—å¹¶å†™å…¥æ•°æ®åº“"
    
    # å£°æ˜Pydanticå­—æ®µ
    url: Optional[str] = None
    key: Optional[str] = None
    client: Optional[Client] = None
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        # åˆå§‹åŒ–Supabaseæ•°æ®åº“è¿æ¥
        self.url = os.getenv("SEO_SUPABASE_URL")
        self.key = os.getenv("SEO_SUPABASE_ANON_KEY")
        
        if self.url and self.key:
            self.client = create_client(self.url, self.key)
        else:
            logger.warning("Supabaseç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œå°†è·³è¿‡æ•°æ®åº“å†™å…¥")
            self.client = None
    
    def _run(self, keyword: str, input_data_dir: str = "data/export", output_data_dir: str = "outputs", method: str = "weighted") -> str:
        """
        è®¡ç®—SOV
        
        Args:
            keyword: å…³é”®è¯
            data_dir: æ•°æ®ç›®å½•
            method: è®¡ç®—æ–¹æ³• (simple/weighted/engagement)
                   - simple: åŸºäºç¬”è®°æ•°é‡çš„ç®€å•å æ¯”
                   - weighted: åŸºäºæœç´¢æ’ååŠ æƒçš„å æ¯”
                   - engagement: åŸºäºäº’åŠ¨é‡åŠ æƒçš„å æ¯”
                   
        Returns:
            SOVè®¡ç®—ç»“æœ
        """
        try:
            logger.info(f"[SOVCalculatorTool] å¼€å§‹è®¡ç®—å…³é”®è¯ '{keyword}' çš„SOVï¼Œæ–¹æ³•: {method}")
            
            # 1. æŸ¥æ‰¾å¯¹åº”çš„CSVæ–‡ä»¶
            csv_file = self._find_csv_file(keyword, input_data_dir)
            if not csv_file:
                return f"æœªæ‰¾åˆ°å…³é”®è¯ '{keyword}' çš„æ•°æ®æ–‡ä»¶ï¼Œè¯·å…ˆä½¿ç”¨DataMergerToolç”Ÿæˆå®½è¡¨æ•°æ®"
            
            # 2. è¯»å–CSVæ•°æ®
            df = pd.read_csv(csv_file)
            logger.info(f"[SOVCalculatorTool] è¯»å–æ•°æ®æ–‡ä»¶: {csv_file}, è®°å½•æ•°: {len(df)}")
            
            # 3. æ•°æ®é¢„å¤„ç†
            processed_df = self._preprocess_data(df)
            
            # 4. åˆ†æ¡£ä½è®¡ç®—SOV
            tier_results = self._calculate_tiered_sov(processed_df, method)
            
            # 5. ä¿å­˜ç»“æœåˆ°CSV
            result_files = self._save_tiered_sov_results(tier_results, keyword, method, output_data_dir)
            
            # 6. å†™å…¥æ•°æ®åº“
            db_write_result = self._write_sov_to_database(tier_results, keyword, method)
            #db_write_result= '123'
            # 7. ç”ŸæˆæŠ¥å‘Š
            report = self._generate_tiered_sov_report(tier_results, keyword, method, len(processed_df))
            
            return f"""âœ… SOVè®¡ç®—å®Œæˆï¼

ğŸ“Š SOVåˆ†ææŠ¥å‘Š:
{report}

ğŸ“ ç»“æœæ–‡ä»¶: {result_files}
ğŸ“ æ•°æ®æº: {csv_file}
ğŸ“ æ•°æ®åº“å†™å…¥: {db_write_result}"""
            
        except Exception as e:
            logger.error(f"[SOVCalculatorTool] SOVè®¡ç®—å¤±è´¥: {e}")
            return f"SOVè®¡ç®—å¤±è´¥: {str(e)}"
    
    def _find_csv_file(self, keyword: str, data_dir: str) -> Optional[str]:
        """æŸ¥æ‰¾æŒ‡å®šå…³é”®è¯çš„æœ€æ–°CSVæ–‡ä»¶"""
        pattern = os.path.join(data_dir+'/'+keyword, f"merged_data_*.csv")
        files = glob.glob(pattern)
        
        if not files:
            return None
        
        # è¿”å›æœ€æ–°çš„æ–‡ä»¶
        latest_file = max(files, key=os.path.getctime)
        logger.info(f"[SOVCalculatorTool] æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {latest_file}")
        return latest_file
    
    def _preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ•°æ®é¢„å¤„ç†"""
        # åªä¿ç•™æœ‰å“ç‰Œä¿¡æ¯çš„è®°å½•
        df_valid = df[df['has_brand_info'] == True].copy()
        
        logger.info(f"[SOVCalculatorTool] æ•°æ®é¢„å¤„ç†: åŸå§‹è®°å½• {len(df)} æ¡ï¼Œæœ‰å“ç‰Œä¿¡æ¯ {len(df_valid)} æ¡")
        
        # å¤„ç†brand_listå­—æ®µ
        expanded_records = []
        
        for _, row in df_valid.iterrows():
            try:
                brand_list_str = row['brand_list']

                if pd.isna(brand_list_str) or brand_list_str == '':
                    continue
                
                # è§£æå“ç‰Œåˆ—è¡¨ - å¤„ç†å¯èƒ½çš„åŒé‡JSONç¼–ç 
                if isinstance(brand_list_str, str):
                    brands = json.loads(brand_list_str)
                    
                    # å¤„ç†åŒé‡ç¼–ç çš„æƒ…å†µ
                    if isinstance(brands, str):
                        try:
                            brands = json.loads(brands)
                            logger.debug(f"åŒé‡è§£ç æˆåŠŸ: {brands}")
                        except (json.JSONDecodeError, TypeError):
                            logger.warning(f"åŒé‡è§£ç å¤±è´¥: {brands}")
                            continue
                            
                else:
                    brands = brand_list_str
                
                if not isinstance(brands, list):
                    continue
                if len(brands) == 0:
                    continue

                #logger.info(f"[SOVCalculatorTool] rank: {row['rank']}ï¼Œbrands:  {brands}")
        
                # ä¸ºæ¯ä¸ªå“ç‰Œåˆ›å»ºä¸€æ¡è®°å½•
                for brand in brands:
                    if brand and brand.strip():
                        # æ ‡å‡†åŒ–å“ç‰Œå
                        brand_normalizer = get_brand_normalizer()
                        normalized_brand = brand_normalizer.normalize_brand_name(brand.strip())
                        
                        if normalized_brand:  # åªæœ‰æ ‡å‡†åŒ–åä¸ä¸ºç©ºçš„å“ç‰Œåæ‰å¤„ç†
                            # å°†pandas Seriesè½¬æ¢ä¸ºå­—å…¸ï¼Œç„¶åæ·»åŠ brandå­—æ®µ
                            record = row.to_dict()
                            record['brand'] = normalized_brand
                            record['original_brand'] = brand.strip()  # ä¿ç•™åŸå§‹å“ç‰Œåç”¨äºè°ƒè¯•
                            expanded_records.append(record)
                        
            except (json.JSONDecodeError, TypeError) as e:
                logger.warning(f"è§£æå“ç‰Œåˆ—è¡¨å¤±è´¥: {e}, æ•°æ®: {row['brand_list']}")
                continue
        
        if not expanded_records:
            logger.warning("[SOVCalculatorTool] æ²¡æœ‰æœ‰æ•ˆçš„å“ç‰Œæ•°æ®")
            return pd.DataFrame()
        
        expanded_df = pd.DataFrame(expanded_records)
        
        # å¡«å……ç¼ºå¤±å€¼
        numeric_columns = ['liked_count', 'collected_count', 'comment_count', 'share_count', 'rank']
        for col in numeric_columns:
            if col in expanded_df.columns:
                expanded_df[col] = pd.to_numeric(expanded_df[col], errors='coerce').fillna(0)
        
        logger.info(f"[SOVCalculatorTool] å±•å¼€åçš„å“ç‰Œè®°å½•: {len(expanded_df)} æ¡ï¼Œæ¶‰åŠå“ç‰Œ: {expanded_df['brand'].nunique()} ä¸ª")
        #ogger.info(f"[SOVCalculatorTool] å±•å¼€åçš„å“ç‰Œè®°å½•: {expanded_df.head(10)}")

        return expanded_df
    
    def _calculate_simple_sov(self, df: pd.DataFrame) -> Dict[str, Any]:
        """è®¡ç®—ç®€å•SOVï¼ˆåŸºäºç¬”è®°æ•°é‡ï¼‰"""

        brand_counts = df['brand'].value_counts()
        total_mentions = len(df)
        
        sov_data = []
        for brand, count in brand_counts.items():
            sov_percentage = (count / total_mentions) * 100
            sov_data.append({
                'brand': brand,
                'mention_count': int(count),
                'sov_percentage': round(sov_percentage, 2),
                'rank': len(sov_data) + 1
            })
        
        return {
            'method': 'simple',
            'total_mentions': total_mentions,
            'unique_brands': len(brand_counts),
            'sov_data': sov_data
        }
    
    def _calculate_weighted_sov(self, df: pd.DataFrame) -> Dict[str, Any]:
        """è®¡ç®—åŠ æƒSOVï¼ˆåŸºäºæœç´¢æ’ååŠ æƒï¼‰"""
        # æ’åæƒé‡ï¼šæ’åè¶Šé å‰æƒé‡è¶Šé«˜
        # æƒé‡å…¬å¼ï¼š1 / rank (æ’åç¬¬1çš„æƒé‡æœ€é«˜)
        df['rank_weight'] = 1 / (df['rank'] + 1)  # +1é¿å…é™¤é›¶
        
        brand_weighted_scores = df.groupby('brand')['rank_weight'].sum()
        total_weight = df['rank_weight'].sum()
        
        sov_data = []
        for brand, weight in brand_weighted_scores.sort_values(ascending=False).items():
            sov_percentage = (weight / total_weight) * 100
            mention_count = len(df[df['brand'] == brand])
            avg_rank = df[df['brand'] == brand]['rank'].mean()
            
            sov_data.append({
                'brand': brand,
                'mention_count': mention_count,
                'weighted_score': round(weight, 4),
                'sov_percentage': round(sov_percentage, 2),
                'avg_rank': round(avg_rank, 2),
                'rank': len(sov_data) + 1
            })
        
        return {
            'method': 'weighted',
            'total_weight': round(total_weight, 4),
            'unique_brands': len(brand_weighted_scores),
            'sov_data': sov_data
        }
    
    def _calculate_engagement_sov(self, df: pd.DataFrame) -> Dict[str, Any]:
        """è®¡ç®—äº’åŠ¨é‡åŠ æƒSOV"""
        # è®¡ç®—æ€»äº’åŠ¨é‡
        df['total_engagement'] = (
            df['liked_count'] + 
            df['collected_count'] + 
            df['comment_count'] + 
            df['share_count']
        )
        
        brand_engagement = df.groupby('brand').agg({
            'total_engagement': 'sum',
            'brand': 'count',  # ç¬”è®°æ•°é‡
            'rank': 'mean'     # å¹³å‡æ’å
        }).rename(columns={'brand': 'mention_count'})
        
        total_engagement = df['total_engagement'].sum()
        
        sov_data = []
        for brand, row in brand_engagement.sort_values('total_engagement', ascending=False).iterrows():
            sov_percentage = (row['total_engagement'] / total_engagement) * 100 if total_engagement > 0 else 0
            
            sov_data.append({
                'brand': brand,
                'mention_count': int(row['mention_count']),
                'total_engagement': int(row['total_engagement']),
                'avg_engagement_per_note': round(row['total_engagement'] / row['mention_count'], 2),
                'sov_percentage': round(sov_percentage, 2),
                'avg_rank': round(row['rank'], 2),
                'rank': len(sov_data) + 1
            })
        
        return {
            'method': 'engagement',
            'total_engagement': int(total_engagement),
            'unique_brands': len(brand_engagement),
            'sov_data': sov_data
        }
    
    def _calculate_tiered_sov(self, df: pd.DataFrame, method: str) -> Dict[str, Any]:
        """åˆ†æ¡£ä½è®¡ç®—SOVï¼ˆtop20ã€top50ã€top100ï¼‰"""
        tiers = {
            'top20': 20,
            'top50': 50, 
            'top100': 100
        }
        
        tier_results = {}
        
        for tier_name, tier_limit in tiers.items():
            logger.info(f"[SOVCalculatorTool] è®¡ç®— {tier_name} SOV...")
            
            # ç­›é€‰å¯¹åº”æ¡£ä½çš„æ•°æ®
            tier_df = df[df['rank'] <= tier_limit].copy()
            
            if tier_df.empty:
                logger.warning(f"[SOVCalculatorTool] {tier_name} æ¡£ä½æ²¡æœ‰æ•°æ®")
                tier_results[tier_name] = {
                    'method': method,
                    'tier': tier_name,
                    'tier_limit': tier_limit,
                    'total_records': 0,
                    'unique_brands': 0,
                    'sov_data': []
                }
                continue
            
            # æ ¹æ®æ–¹æ³•è®¡ç®—SOV
            if method == "simple":
                sov_result = self._calculate_simple_sov(tier_df)
            elif method == "weighted":
                sov_result = self._calculate_weighted_sov(tier_df)
            elif method == "engagement":
                sov_result = self._calculate_engagement_sov(tier_df)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„è®¡ç®—æ–¹æ³•: {method}")
            
            # æ·»åŠ æ¡£ä½ä¿¡æ¯
            sov_result['tier'] = tier_name
            sov_result['tier_limit'] = tier_limit
            sov_result['total_records'] = len(tier_df)
            
            tier_results[tier_name] = sov_result
            
            logger.info(f"[SOVCalculatorTool] {tier_name} SOVè®¡ç®—å®Œæˆï¼Œè®°å½•æ•°: {len(tier_df)}, å“ç‰Œæ•°: {sov_result['unique_brands']}")
        
        return tier_results
    
    def _save_tiered_sov_results(self, tier_results: Dict[str, Any], keyword: str, method: str, data_dir: str) -> str:
        """ä¿å­˜åˆ†æ¡£ä½SOVè®¡ç®—ç»“æœåˆ°CSV"""
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = os.path.join(data_dir, keyword)
        os.makedirs(output_dir, exist_ok=True)
        
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%Y%m%d")
        
        result_files = []
        
        # åˆå¹¶æ‰€æœ‰æ¡£ä½çš„æ•°æ®åˆ°ä¸€ä¸ªCSVæ–‡ä»¶
        all_sov_data = []
        
        for tier_name, tier_data in tier_results.items():
            if not tier_data.get('sov_data'):
                logger.warning(f"[SOVCalculatorTool] {tier_name} æ¡£ä½æ²¡æœ‰SOVæ•°æ®ï¼Œè·³è¿‡")
                continue
            
            # ä¸ºæ¯æ¡è®°å½•æ·»åŠ æ¡£ä½ä¿¡æ¯
            for sov_record in tier_data['sov_data']:
                record = sov_record.copy()
                record['keyword'] = keyword
                record['method'] = method
                record['tier'] = tier_name
                record['tier_limit'] = tier_data['tier_limit']
                record['total_records'] = tier_data['total_records']
                record['calculated_at'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                all_sov_data.append(record)
        
        if all_sov_data:
            # CSVæ–‡ä»¶å
            csv_filename = f"SOV_all_tiers_{method}_{timestamp}.csv"
            csv_filepath = os.path.join(output_dir, csv_filename)
            
            # åˆ›å»ºDataFrame
            sov_df = pd.DataFrame(all_sov_data)
            
            # é‡æ–°æ’åˆ—åˆ—é¡ºåº
            columns_order = ['keyword', 'method', 'tier', 'tier_limit', 'rank', 'brand', 'mention_count', 'sov_percentage']
            
            # æ ¹æ®è®¡ç®—æ–¹æ³•æ·»åŠ ç‰¹å®šåˆ—
            if method == 'weighted':
                columns_order.extend(['weighted_score', 'avg_rank'])
            elif method == 'engagement':
                columns_order.extend(['total_engagement', 'avg_engagement_per_note', 'avg_rank'])
            
            columns_order.extend(['total_records', 'calculated_at'])
            
            # ç­›é€‰å­˜åœ¨çš„åˆ—
            available_columns = [col for col in columns_order if col in sov_df.columns]
            sov_df = sov_df[available_columns]
            
            # ä¿å­˜CSV
            sov_df.to_csv(csv_filepath, index=False, encoding='utf-8-sig')
            result_files.append(csv_filepath)
            
            logger.info(f"[SOVCalculatorTool] æ‰€æœ‰æ¡£ä½SOVç»“æœå·²ä¿å­˜: {csv_filepath}")
        
        # åŒæ—¶ä¿å­˜åˆå¹¶çš„JSONæ–‡ä»¶
        json_filename = f"SOV_all_tiers_{method}_{timestamp}.json"
        json_filepath = os.path.join(output_dir, json_filename)
        
        # æ·»åŠ å…ƒæ•°æ®
        tier_results['metadata'] = {
            'keyword': keyword,
            'method': method,
            'calculated_at': datetime.now().isoformat(),
            'tool_version': '2.0'
        }
        
        with open(json_filepath, 'w', encoding='utf-8') as f:
            json.dump(tier_results, f, ensure_ascii=False, indent=2)
        
        result_files.append(json_filepath)
        logger.info(f"[SOVCalculatorTool] åˆå¹¶JSONç»“æœå·²ä¿å­˜: {json_filepath}")
        
        return ", ".join(result_files)
    
    def _generate_tiered_sov_report(self, tier_results: Dict[str, Any], keyword: str, method: str, total_records: int) -> str:
        """ç”Ÿæˆåˆ†æ¡£ä½SOVæŠ¥å‘Š"""
        if not tier_results:
            return "æ²¡æœ‰æ‰¾åˆ°SOVæ•°æ®"
        
        report_lines = []
        report_lines.append(f"å…³é”®è¯: {keyword}")
        report_lines.append(f"è®¡ç®—æ–¹æ³•: {method}")
        report_lines.append(f"æ€»è®°å½•æ•°: {total_records}")
        report_lines.append("")
        
        # ä¸ºæ¯ä¸ªæ¡£ä½ç”ŸæˆæŠ¥å‘Š
        for tier_name in ['top20', 'top50', 'top100']:
            if tier_name not in tier_results:
                continue
                
            tier_data = tier_results[tier_name]
            sov_data = tier_data.get('sov_data', [])
            
            if not sov_data:
                report_lines.append(f"ğŸ† {tier_name.upper()} æ¡£ä½: æ— æ•°æ®")
                report_lines.append("")
                continue
            
            report_lines.append(f"ğŸ† {tier_name.upper()} æ¡£ä½ (å‰{tier_data['tier_limit']}å):")
            report_lines.append(f"   è®°å½•æ•°: {tier_data['total_records']}, æ¶‰åŠå“ç‰Œæ•°: {tier_data['unique_brands']}")
            report_lines.append("-" * 60)
            
            # æ˜¾ç¤ºå‰10åå“ç‰Œ
            top_brands = sov_data[:10]
            
            if method == 'simple':
                for item in top_brands:
                    report_lines.append(
                        f"   {item['rank']:2d}. {item['brand']:<20} | "
                        f"ç¬”è®°æ•°: {item['mention_count']:3d} | "
                        f"SOV: {item['sov_percentage']:6.2f}%"
                    )
            elif method == 'weighted':
                for item in top_brands:
                    report_lines.append(
                        f"   {item['rank']:2d}. {item['brand']:<20} | "
                        f"ç¬”è®°æ•°: {item['mention_count']:3d} | "
                        f"å¹³å‡æ’å: {item['avg_rank']:5.2f} | "
                        f"SOV: {item['sov_percentage']:6.2f}%"
                    )
            elif method == 'engagement':
                for item in top_brands:
                    report_lines.append(
                        f"   {item['rank']:2d}. {item['brand']:<20} | "
                        f"ç¬”è®°æ•°: {item['mention_count']:3d} | "
                        f"æ€»äº’åŠ¨: {item['total_engagement']:6d} | "
                        f"SOV: {item['sov_percentage']:6.2f}%"
                    )
            
            # æ·»åŠ å¸‚åœºé›†ä¸­åº¦åˆ†æ
            if len(sov_data) >= 3:
                top3_sov = sum(item['sov_percentage'] for item in sov_data[:3])
                top5_sov = sum(item['sov_percentage'] for item in sov_data[:5]) if len(sov_data) >= 5 else top3_sov
                
                report_lines.append("")
                report_lines.append(f"   ğŸ“ˆ {tier_name.upper()} å¸‚åœºé›†ä¸­åº¦:")
                report_lines.append(f"   - Top 3 å“ç‰ŒSOVæ€»å’Œ: {top3_sov:.2f}%")
                if len(sov_data) >= 5:
                    report_lines.append(f"   - Top 5 å“ç‰ŒSOVæ€»å’Œ: {top5_sov:.2f}%")
                
                # å¸‚åœºé›†ä¸­åº¦åˆ¤æ–­
                if top3_sov > 60:
                    concentration = "é«˜åº¦é›†ä¸­"
                elif top3_sov > 40:
                    concentration = "ä¸­åº¦é›†ä¸­"
                else:
                    concentration = "åˆ†æ•£ç«äº‰"
                
                report_lines.append(f"   - å¸‚åœºé›†ä¸­åº¦: {concentration}")
            
            report_lines.append("")
        
        # æ·»åŠ æ¡£ä½å¯¹æ¯”åˆ†æ
        if len(tier_results) > 1:
            report_lines.append("ğŸ“Š æ¡£ä½å¯¹æ¯”åˆ†æ:")
            report_lines.append("-" * 60)
            
            # æ‰¾å‡ºåœ¨æ‰€æœ‰æ¡£ä½éƒ½å‡ºç°çš„å“ç‰Œ
            all_brands = set()
            for tier_data in tier_results.values():
                if isinstance(tier_data, dict) and 'sov_data' in tier_data:
                    for item in tier_data['sov_data']:
                        all_brands.add(item['brand'])
            
            # æ˜¾ç¤ºä¸»è¦å“ç‰Œåœ¨ä¸åŒæ¡£ä½çš„è¡¨ç°
            main_brands = list(all_brands)[:5]  # å–å‰5ä¸ªå“ç‰Œè¿›è¡Œå¯¹æ¯”
            
            for brand in main_brands:
                brand_performance = []
                for tier_name in ['top20', 'top50', 'top100']:
                    if tier_name in tier_results:
                        tier_data = tier_results[tier_name]
                        for item in tier_data.get('sov_data', []):
                            if item['brand'] == brand:
                                brand_performance.append(f"{tier_name}: {item['sov_percentage']:.2f}%")
                                break
                
                if brand_performance:
                    report_lines.append(f"   {brand}: {' | '.join(brand_performance)}")
        
        return "\n".join(report_lines)
    
    def _write_sov_to_database(self, tier_results: Dict[str, Any], keyword: str, method: str) -> str:
        """å°†SOVç»“æœå†™å…¥Supabaseæ•°æ®åº“è¡¨xhs_keyword_sov_result"""
        if not self.client:
            return "âŒ æ•°æ®åº“è¿æ¥æœªåˆå§‹åŒ–ï¼Œè·³è¿‡æ•°æ®åº“å†™å…¥"
        
        try:
            logger.info(f"[SOVCalculatorTool] å¼€å§‹å†™å…¥SOVç»“æœåˆ°æ•°æ®åº“...")
            
            # å‡†å¤‡è¦æ’å…¥çš„æ•°æ®
            data_to_insert = []
            
            for tier_name, tier_data in tier_results.items():
                if tier_name == 'metadata':  # è·³è¿‡å…ƒæ•°æ®
                    continue
                    
                if not tier_data.get('sov_data'):
                    logger.warning(f"[SOVCalculatorTool] {tier_name} æ¡£ä½æ²¡æœ‰SOVæ•°æ®ï¼Œè·³è¿‡å†™å…¥")
                    continue
                
                for sov_item in tier_data['sov_data']:
                    # å¤„ç†å¯èƒ½ä¸ºç©ºæˆ–NaNçš„æ•°å€¼å­—æ®µ
                    def safe_float(value, default=0.0):
                        try:
                            if pd.isna(value) or value == '' or value is None:
                                return default
                            return float(value)
                        except (ValueError, TypeError):
                            return default
                    
                    def safe_int(value, default=0):
                        try:
                            if pd.isna(value) or value == '' or value is None:
                                return default
                            return int(float(value))
                        except (ValueError, TypeError):
                            return default
                    
                    def safe_str(value, default=""):
                        try:
                            if pd.isna(value) or value is None:
                                return default
                            return str(value)
                        except:
                            return default
                    
                    record = {
                        "keyword": safe_str(keyword),
                        #"method": safe_str(method),
                        #"tier": safe_str(tier_name),
                        "tier_limit": safe_int(tier_data.get('tier_limit')),
                        "brand": safe_str(sov_item.get('brand')),
                        "rank": safe_int(sov_item.get('rank')),
                        "sov_percentage": safe_float(sov_item.get('sov_percentage')),
                        "mention_count": safe_int(sov_item.get('mention_count')),
                        "total_records": safe_int(tier_data.get('total_records')),
                        "unique_brands": safe_int(tier_data.get('unique_brands')),
                        #"created_at": datetime.now().isoformat(),
                        #"updated_at": datetime.now().isoformat()
                    }
                    
                    # æ ¹æ®è®¡ç®—æ–¹æ³•æ·»åŠ ç‰¹å®šå­—æ®µ
                    if method == 'weighted':
                        record["weighted_score"] = safe_float(sov_item.get('weighted_score'))
                        record["avg_rank"] = safe_float(sov_item.get('avg_rank'))
                    elif method == 'engagement':
                        record["total_engagement"] = safe_int(sov_item.get('total_engagement'))
                        record["avg_engagement_per_note"] = safe_float(sov_item.get('avg_engagement_per_note'))
                        record["avg_rank"] = safe_float(sov_item.get('avg_rank'))
                    
                    data_to_insert.append(record)
            
            if not data_to_insert:
                return "âŒ æ²¡æœ‰SOVæ•°æ®éœ€è¦å†™å…¥æ•°æ®åº“"
            
            # æ‰¹é‡æ’å…¥æ•°æ®åˆ°ç›®æ ‡è¡¨
            response = (
                self.client.table("xhs_keyword_sov_result")
                .insert(data_to_insert)
                .execute()
            )
            
            if response.data:
                success_count = len(response.data)
                logger.info(f"[SOVCalculatorTool] âœ… æˆåŠŸå†™å…¥ {success_count} æ¡SOVè®°å½•åˆ°æ•°æ®åº“")
                return f"âœ… æˆåŠŸå†™å…¥ {success_count} æ¡SOVè®°å½•åˆ°æ•°æ®åº“"
            else:
                logger.warning(f"[SOVCalculatorTool] âš ï¸ æ•°æ®åº“å†™å…¥å®Œæˆï¼Œä½†æœªè¿”å›æ’å…¥è®°å½•æ•°")
                return f"âœ… æ•°æ®åº“å†™å…¥å®Œæˆï¼ˆ{len(data_to_insert)} æ¡è®°å½•ï¼‰"
            
        except Exception as e:
            error_msg = f"å†™å…¥æ•°æ®åº“å¤±è´¥: {str(e)}"
            logger.error(f"[SOVCalculatorTool] âŒ {error_msg}")
            return f"âŒ {error_msg}" 