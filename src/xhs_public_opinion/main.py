#!/usr/bin/env python
import sys
import warnings
import os
import json
import re
from datetime import datetime
from dotenv import load_dotenv
import logging


from xhs_public_opinion.crew import XhsPublicOpinionCrew
from xhs_public_opinion.tools import (
    DatabaseReaderTool,
    DatabaseWriterTool
)
from xhs_public_opinion.config.batch_config import BatchConfig

logger = logging.getLogger(__name__)

warnings.filterwarnings("ignore", category=SyntaxWarning, module="pysbd")

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# This main file is intended to be a way for you to run your
# crew locally, so refrain from adding unnecessary logic into this file.
# Replace with inputs you want to test with, it will automatically
# interpolate any tasks and agents information

def run():
    """
    è¿è¡Œå°çº¢ä¹¦å…¬å…±èˆ†æƒ…åˆ†æï¼ˆé‡æ„ç‰ˆæœ¬ï¼šæ•°æ®åº“æ‰¹é‡æ“ä½œï¼ŒAIåˆ†æ‰¹å¤„ç†ï¼‰
    æµç¨‹ï¼šå¤§æ‰¹é‡æ•°æ®åº“è¯»å– â†’ åˆ†æ‰¹AIå†…å®¹åˆ†æ â†’ æ‰¹é‡æ•°æ®åº“å†™å…¥
    """
    # æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡
    required_env_vars = ['SEO_SUPABASE_URL', 'SEO_SUPABASE_ANON_KEY', 'OPENROUTER_API_KEY']
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]
    
    if missing_vars:
        print(f"é”™è¯¯ï¼šç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")
        print("è¯·åˆ›å»º .env æ–‡ä»¶å¹¶è®¾ç½®ä»¥ä¸‹å˜é‡ï¼š")
        print("SEO_SUPABASE_URL=your_supabase_url")
        print("SEO_SUPABASE_ANON_KEY=your_supabase_anon_key") 
        print("OPENROUTER_API_KEY=your_openrouter_api_key")
        return None
    
    # ä½¿ç”¨é…ç½®ç±»è·å–æ‰¹æ¬¡å¤§å°
    db_batch_size, ai_batch_size = BatchConfig.validate_and_adjust()
    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    try:
        print("ğŸš€ å¼€å§‹æ‰§è¡Œå°çº¢ä¹¦å…¬å…±èˆ†æƒ…åˆ†æï¼ˆæ‰¹é‡æ•°æ®åº“+åˆ†æ‰¹AIå¤„ç†ï¼‰...")
        print(f"ğŸ“… åˆ†ææ—¶é—´: {current_time}")
        print(BatchConfig.get_config_summary())
        print("="*60)
        
        # ==================== é˜¶æ®µ1ï¼šæ‰¹é‡æ•°æ®åº“è¯»å– ====================
        print("ğŸ“– é˜¶æ®µ1: æ‰¹é‡æ•°æ®åº“è¯»å–...")
        db_reader = DatabaseReaderTool()
        raw_data = db_reader._run(batch_size=db_batch_size)
        
        # æ£€æŸ¥è¯»å–ç»“æœ
        if not raw_data or "æ²¡æœ‰æ‰¾åˆ°æœªå¤„ç†çš„ç¬”è®°æ•°æ®" in raw_data:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æœªå¤„ç†çš„æ•°æ®ï¼Œåˆ†æç»“æŸ")
            return {
                "status": "no_data",
                "message": "æ²¡æœ‰æ‰¾åˆ°æœªå¤„ç†çš„ç¬”è®°æ•°æ®",
                "timestamp": datetime.now().isoformat()
            }
        
        # è§£æè¯»å–çš„æ•°æ®
        try:
            notes_data = json.loads(raw_data)
            total_notes_count = notes_data.get('total_count', 0)
            all_notes_list = notes_data.get('notes', [])
            
            if total_notes_count == 0:
                print("âš ï¸ è¯»å–åˆ°çš„æ•°æ®ä¸ºç©ºï¼Œåˆ†æç»“æŸ")
                return {
                    "status": "empty_data",
                    "message": "è¯»å–åˆ°çš„æ•°æ®ä¸ºç©º",
                    "timestamp": datetime.now().isoformat()
                }
            
            print(f"âœ… æ•°æ®è¯»å–å®Œæˆ! å…±è·å– {total_notes_count} æ¡ç¬”è®°æ•°æ®")
            print(f"ğŸ“‹ å°†åˆ†æ‰¹è¿›è¡ŒAIåˆ†æï¼Œæ¯æ‰¹ {ai_batch_size} æ¡")
            
        except json.JSONDecodeError as e:
            print(f"âŒ æ•°æ®è§£æå¤±è´¥: {e}")
            return None
        
        # ==================== é˜¶æ®µ2ï¼šåˆ†æ‰¹AIå†…å®¹åˆ†æ + å³æ—¶å†™å…¥ ====================
        print("\n" + "="*60)
        print("ğŸ¤– é˜¶æ®µ2: åˆ†æ‰¹æ‰§è¡ŒAIå†…å®¹åˆ†æ + å³æ—¶æ•°æ®åº“å†™å…¥...")
        
        total_analysis_results = 0  # è®°å½•æ€»çš„åˆ†æç»“æœæ•°é‡
        total_written_results = 0   # è®°å½•æ€»çš„å†™å…¥æˆåŠŸæ•°é‡
        failed_batches = []         # è®°å½•å¤±è´¥çš„æ‰¹æ¬¡
        successful_batches = []     # è®°å½•æˆåŠŸçš„æ‰¹æ¬¡
        
        # åˆå§‹åŒ–æ•°æ®åº“å†™å…¥å·¥å…·ï¼ˆå¤ç”¨åŒä¸€ä¸ªå®ä¾‹ï¼‰
        db_writer = DatabaseWriterTool()
        
        # å°†æ•°æ®åˆ†æ‰¹å¤„ç†
        for batch_index in range(0, total_notes_count, ai_batch_size):
            batch_end = min(batch_index + ai_batch_size, total_notes_count)
            current_batch = all_notes_list[batch_index:batch_end]
            batch_number = (batch_index // ai_batch_size) + 1
            total_batches = (total_notes_count + ai_batch_size - 1) // ai_batch_size
            
            print(f"\nğŸ”„ å¤„ç†ç¬¬ {batch_number}/{total_batches} æ‰¹ (ç´¢å¼• {batch_index}~{batch_end-1}, å…± {len(current_batch)} æ¡)")
            
            try:
                # ===== AIåˆ†æé˜¶æ®µ =====
                # å‡†å¤‡crewè¾“å…¥
                crew_inputs = {
                    'analysis_type': f'å°çº¢ä¹¦ç¬”è®°æƒ…æ„Ÿåˆ†æ - ç¬¬{batch_number}æ‰¹',
                    'current_date': current_time,
                    'batch_size': len(current_batch),
                    'notes': current_batch
                }
                
                print(f"ğŸ“‹ å¼€å§‹AIåˆ†æ: {len(current_batch)} æ¡ç¬”è®°")
                print(f"ğŸ“‹ å¼€å§‹AIåˆ†æ crew_inputs: {crew_inputs}")
                
                # æ‰§è¡ŒAIåˆ†æcrew
                crew_result = XhsPublicOpinionCrew().crew().kickoff(inputs=crew_inputs)
                
                if not crew_result:
                    print(f"âŒ ç¬¬{batch_number}æ‰¹AIåˆ†æå¤±è´¥ï¼šæ²¡æœ‰è¿”å›ç»“æœ")
                    failed_batches.append({
                        'batch': batch_number,
                        'error': 'AIåˆ†ææ— è¿”å›ç»“æœ',
                        'note_count': len(current_batch)
                    })
                    continue
                    
                print(f"âœ… ç¬¬{batch_number}æ‰¹AIåˆ†æå®Œæˆ!")
                analysis_json = str(crew_result)
                print(f"ğŸ“Š åˆ†æç»“æœé•¿åº¦: {len(analysis_json)} å­—ç¬¦")
                
                # è§£æåˆ†æç»“æœ
                try:
                    if isinstance(crew_result, str):
                        batch_results = json.loads(analysis_json)
                    else:
                        batch_results = json.loads(str(crew_result))
                    
                    if not isinstance(batch_results, list):
                        print(f"âš ï¸ ç¬¬{batch_number}æ‰¹ç»“æœæ ¼å¼ä¸æ­£ç¡®ï¼ˆéæ•°ç»„ï¼‰ï¼Œè·³è¿‡")
                        failed_batches.append({
                            'batch': batch_number,
                            'error': 'ç»“æœæ ¼å¼ä¸æ­£ç¡®',
                            'note_count': len(current_batch)
                        })
                        continue
                    
                    # åˆ†ç¦»æˆåŠŸå’Œå¤±è´¥çš„ç»“æœ
                    successful_results = []
                    failed_results = []
                    
                    for i, result in enumerate(batch_results):
                        try:
                            # æ£€æŸ¥æ˜¯å¦ä¸ºå¤±è´¥çš„ç»“æœ
                            if isinstance(result, dict) and result.get('_analysis_failed', False):
                                failed_results.append({
                                    'index': i,
                                    'error_type': result.get('_error_type', 'unknown'),
                                    'error_message': result.get('_error_message', 'unknown error')
                                })
                                logger.warning(f"[Main] ç¬¬{batch_number}æ‰¹ç¬¬{i+1}æ¡ç»“æœåˆ†æå¤±è´¥: {result.get('_error_message', 'unknown')}")
                            else:
                                # ç§»é™¤å¯èƒ½å­˜åœ¨çš„å¤±è´¥æ ‡è®°å­—æ®µï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                                cleaned_result = {k: v for k, v in result.items() if not k.startswith('_analysis_')}
                                successful_results.append(cleaned_result)
                        except Exception as e:
                            failed_results.append({
                                'index': i,
                                'error_type': 'result_processing_error',
                                'error_message': f'ç»“æœå¤„ç†é”™è¯¯: {str(e)}'
                            })
                            logger.warning(f"[Main] ç¬¬{batch_number}æ‰¹ç¬¬{i+1}æ¡ç»“æœå¤„ç†å¤±è´¥: {e}")
                    
                    total_analysis_results += len(batch_results)
                    success_count = len(successful_results)
                    fail_count = len(failed_results)
                    
                    print(f"ğŸ“Š ç¬¬{batch_number}æ‰¹è§£æå®Œæˆ: æ€»è®¡ {len(batch_results)} æ¡ï¼ŒæˆåŠŸ {success_count} æ¡ï¼Œå¤±è´¥ {fail_count} æ¡")
                    
                    if fail_count > 0:
                        print(f"âš ï¸ ç¬¬{batch_number}æ‰¹å¤±è´¥è¯¦æƒ…:")
                        for fail_info in failed_results[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªå¤±è´¥ä¿¡æ¯
                            print(f"   - ç¬¬{fail_info['index']+1}æ¡: {fail_info['error_type']} - {fail_info['error_message'][:50]}...")
                        if fail_count > 3:
                            print(f"   - è¿˜æœ‰ {fail_count-3} æ¡å¤±è´¥...")
                    
                    # å¦‚æœæ²¡æœ‰æˆåŠŸçš„ç»“æœï¼Œè·³è¿‡å†™å…¥
                    if not successful_results:
                        print(f"âŒ ç¬¬{batch_number}æ‰¹æ²¡æœ‰å¯å†™å…¥çš„æˆåŠŸç»“æœ")
                        failed_batches.append({
                            'batch': batch_number,
                            'error': 'æ‰¹æ¬¡å†…æ‰€æœ‰ç»“æœéƒ½è§£æå¤±è´¥',
                            'note_count': len(current_batch),
                            'success_count': 0,
                            'fail_count': fail_count
                        })
                        continue
                    
                except json.JSONDecodeError as e:
                    print(f"âš ï¸ ç¬¬{batch_number}æ‰¹ç»“æœè§£æå¤±è´¥: {e}")
                    print(f"åŸå§‹ç»“æœé¢„è§ˆ: {analysis_json[:200]}...")
                    failed_batches.append({
                        'batch': batch_number,
                        'error': f'JSONè§£æå¤±è´¥: {e}',
                        'note_count': len(current_batch)
                    })
                    continue
                
                # ===== ç«‹å³æ•°æ®åº“å†™å…¥é˜¶æ®µï¼ˆåªå†™å…¥æˆåŠŸçš„ç»“æœï¼‰=====
                print(f"ğŸ’¾ ç«‹å³å†™å…¥ç¬¬{batch_number}æ‰¹æˆåŠŸç»“æœåˆ°æ•°æ®åº“ï¼ˆ{len(successful_results)} æ¡ï¼‰...")
                
                # å°†æˆåŠŸçš„ç»“æœè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
                success_batch_json = json.dumps(successful_results, ensure_ascii=False)
                print(f"ğŸ“‹ ç«‹å³å†™å…¥æ•°æ®åº“ success_batch_json: {success_batch_json}")

                
                # ç«‹å³å†™å…¥æ•°æ®åº“
                write_result = db_writer._run(success_batch_json)
                
                # è§£æå†™å…¥ç»“æœ
                if "æˆåŠŸå†™å…¥" in write_result or "âœ…" in write_result:
                    # ä»å†™å…¥ç»“æœä¸­æå–æˆåŠŸæ•°é‡ï¼ˆç®€å•çš„å­—ç¬¦ä¸²åŒ¹é…ï¼‰
                    success_match = re.search(r'æˆåŠŸå†™å…¥[ï¼š:]\s*(\d+)', write_result)
                    if success_match:
                        batch_written_count = int(success_match.group(1))
                    else:
                        batch_written_count = len(successful_results)  # å‡è®¾å…¨éƒ¨æˆåŠŸ
                    
                    total_written_results += batch_written_count
                    successful_batches.append({
                        'batch': batch_number,
                        'analyzed': len(batch_results),
                        'successful_analyzed': len(successful_results),
                        'failed_analyzed': len(failed_results),
                        'written': batch_written_count
                    })
                    print(f"âœ… ç¬¬{batch_number}æ‰¹æ•°æ®åº“å†™å…¥å®Œæˆ: {batch_written_count} æ¡")
                else:
                    batch_written_count = 0  # å†™å…¥å¤±è´¥æ—¶è®¾ç½®ä¸º0
                    print(f"âŒ ç¬¬{batch_number}æ‰¹æ•°æ®åº“å†™å…¥å¤±è´¥")
                    failed_batches.append({
                        'batch': batch_number,
                        'error': 'æ•°æ®åº“å†™å…¥å¤±è´¥',
                        'note_count': len(current_batch),
                        'success_count': len(successful_results),
                        'fail_count': len(failed_results)
                    })
                
                print(f"ğŸ“Š ç¬¬{batch_number}æ‰¹å¤„ç†ç»“æœ: AIåˆ†æ {len(batch_results)} æ¡ â†’ æˆåŠŸ {len(successful_results)} æ¡ â†’ æ•°æ®åº“å†™å…¥ {batch_written_count} æ¡")
                    
            except Exception as e:
                print(f"âŒ ç¬¬{batch_number}æ‰¹å¤„ç†å‡ºé”™: {e}")
                failed_batches.append({
                    'batch': batch_number,
                    'error': str(e),
                    'note_count': len(current_batch)
                })
                continue
        
        # ==================== å¤„ç†ç»“æœç»Ÿè®¡ ====================
        print(f"\nğŸ“Š åˆ†æ‰¹å¤„ç†å®Œæˆç»Ÿè®¡:")
        print(f"âœ… æˆåŠŸæ‰¹æ¬¡: {len(successful_batches)}")
        print(f"âŒ å¤±è´¥æ‰¹æ¬¡: {len(failed_batches)}")
        print(f"ğŸ“ˆ æ€»AIåˆ†æç»“æœ: {total_analysis_results} æ¡")
        print(f"ğŸ’¾ æ€»æ•°æ®åº“å†™å…¥: {total_written_results} æ¡")
        
        # ==================== æ‰§è¡Œæ€»ç»“ ====================
        print("\n" + "="*60)
        print("ğŸ“‹ æ‰§è¡Œæ€»ç»“:")
        print(f"âœ… æ•°æ®åº“è¯»å–é˜¶æ®µ: å®Œæˆ (è¯»å– {total_notes_count} æ¡è®°å½•)")
        print(f"âœ… AIå†…å®¹åˆ†æé˜¶æ®µ: å®Œæˆ (åˆ† {(total_notes_count + ai_batch_size - 1) // ai_batch_size} æ‰¹å¤„ç†)")
        print(f"âœ… æ•°æ®åº“å†™å…¥é˜¶æ®µ: å®Œæˆ (å†™å…¥ {total_written_results} æ¡åˆ†æç»“æœ)") 
        print(f"â° æ€»æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*60)
        
        return {
            "status": "success",
            "data_read_count": total_notes_count,
            "analysis_batches": (total_notes_count + ai_batch_size - 1) // ai_batch_size,
            "analysis_results_count": total_analysis_results,
            "final_results": {
                "successful_batches": successful_batches,
                "failed_batches": failed_batches
            },
            "timestamp": datetime.now().isoformat()
        }

    except Exception as e:
        print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("è¯¦ç»†é”™è¯¯ä¿¡æ¯è¯·æŸ¥çœ‹æ—¥å¿—")
        return None

def train():
    """
    è®­ç»ƒcrewæ¨¡å‹
    """
    if len(sys.argv) < 3:
        print("ä½¿ç”¨æ–¹æ³•: python -m xhs_public_opinion.main train <è¿­ä»£æ¬¡æ•°> <è®­ç»ƒæ–‡ä»¶å>")
        return None
        
    inputs = {
        "analysis_type": "å°çº¢ä¹¦ç¬”è®°æƒ…æ„Ÿåˆ†æè®­ç»ƒ"
    }
    try:
        print(f"ğŸ¯ å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼Œè¿­ä»£æ¬¡æ•°: {sys.argv[1]}")
        result = XhsPublicOpinionCrew().crew().train(
            n_iterations=int(sys.argv[1]), 
            filename=sys.argv[2], 
            inputs=inputs
        )
        print("âœ… è®­ç»ƒå®Œæˆ!")
        return result

    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("è¯¦ç»†é”™è¯¯ä¿¡æ¯è¯·æŸ¥çœ‹æ—¥å¿—")
        return None

def replay():
    """
    é‡æ”¾crewæ‰§è¡Œè¿‡ç¨‹
    """
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python -m xhs_public_opinion.main replay <ä»»åŠ¡ID>")
        return None
        
    try:
        print(f"ğŸ”„ å¼€å§‹é‡æ”¾ä»»åŠ¡: {sys.argv[1]}")
        result = XhsPublicOpinionCrew().crew().replay(task_id=sys.argv[1])
        print("âœ… é‡æ”¾å®Œæˆ!")
        return result

    except Exception as e:
        print(f"âŒ é‡æ”¾è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("è¯¦ç»†é”™è¯¯ä¿¡æ¯è¯·æŸ¥çœ‹æ—¥å¿—")
        return None

def test():
    """
    æµ‹è¯•crewåŠŸèƒ½
    """
    try:
        print("ğŸ§ª å¼€å§‹æµ‹è¯•crewåŠŸèƒ½...")
        result = XhsPublicOpinionCrew().crew().test(
            n_iterations=1,
            openai_model_name="gpt-4o-mini"
        )
        print("âœ… æµ‹è¯•å®Œæˆ!")
        return result

    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("è¯¦ç»†é”™è¯¯ä¿¡æ¯è¯·æŸ¥çœ‹æ—¥å¿—")
        return None

if __name__ == "__main__":
    if len(sys.argv) > 1:
        command = sys.argv[1]
        if command == "train":
            train()
        elif command == "replay": 
            replay()
        elif command == "test":
            test()
        else:
            print("æœªçŸ¥å‘½ä»¤ï¼Œä½¿ç”¨ run() æ‰§è¡Œé»˜è®¤åˆ†æ")
            run()
    else:
        run()
