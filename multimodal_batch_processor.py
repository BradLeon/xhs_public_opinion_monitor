#!/usr/bin/env python
"""
å¤šæ¨¡æ€æ•°æ®æ‰¹å¤„ç†å™¨
ä¸“é—¨å¤„ç†åŒ…å«å›¾ç‰‡å’Œè§†é¢‘çš„å°çº¢ä¹¦ç¬”è®°æ•°æ®
"""

import json
import sys
import os
from datetime import datetime
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('src')

from xhs_public_opinion.tools import (
    DatabaseReaderTool,
    DatabaseWriterTool,
    MultimodalBrandAnalyzer
)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class MultimodalBatchProcessor:
    """å¤šæ¨¡æ€æ‰¹å¤„ç†å™¨"""
    
    def __init__(self):
        self.db_reader = DatabaseReaderTool()
        self.db_writer = DatabaseWriterTool()
        self.analyzer = MultimodalBrandAnalyzer()
        
    def process_multimodal_data(self, batch_size: int = 50):
        """å¤„ç†å¤šæ¨¡æ€æ•°æ®"""
        print("ğŸ¬ å¼€å§‹å¤šæ¨¡æ€æ•°æ®æ‰¹å¤„ç†...")
        print(f"ğŸ“‹ æ‰¹å¤„ç†å¤§å°: {batch_size}")
        
        try:
            # è¯»å–æœªå¤„ç†çš„æ•°æ®
            raw_data = self.db_reader._run(batch_size=batch_size)
            if not raw_data or "æ²¡æœ‰æ‰¾åˆ°æœªå¤„ç†çš„ç¬”è®°æ•°æ®" in raw_data:
                print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æœªå¤„ç†çš„æ•°æ®")
                return False
            
            # è§£ææ•°æ®
            notes_data = json.loads(raw_data)
            all_notes = notes_data.get('notes', [])
            
            if not all_notes:
                print("âš ï¸ æ•°æ®ä¸ºç©º")
                return False
            
            # åˆ†ç±»å¤„ç†ä¸åŒç±»å‹çš„å†…å®¹
            self._classify_and_process(all_notes)
            
            return True
            
        except Exception as e:
            print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            return False
    
    def _classify_and_process(self, all_notes: list):
        """åˆ†ç±»å’Œå¤„ç†ä¸åŒç±»å‹çš„å†…å®¹"""
        # æŒ‰å†…å®¹ç±»å‹åˆ†ç±»
        text_only_notes = []      # çº¯æ–‡æœ¬
        image_notes = []          # åŒ…å«å›¾ç‰‡
        video_notes = []          # åŒ…å«è§†é¢‘
        complex_notes = []        # å›¾ç‰‡+è§†é¢‘
        
        for note in all_notes:
            has_images = note.get('image_list') and len(note.get('image_list', [])) > 0
            has_video = note.get('type') == 'video' and note.get('video_url')
            
            if has_images and has_video:
                complex_notes.append(note)
            elif has_video:
                video_notes.append(note)
            elif has_images:
                image_notes.append(note)
            else:
                text_only_notes.append(note)
        
        # æ‰“å°åˆ†ç±»ç»Ÿè®¡
        print(f"\nğŸ“Š å†…å®¹åˆ†ç±»ç»Ÿè®¡:")
        print(f"   ğŸ“ çº¯æ–‡æœ¬: {len(text_only_notes)} æ¡")
        print(f"   ğŸ–¼ï¸  åŒ…å«å›¾ç‰‡: {len(image_notes)} æ¡")
        print(f"   ğŸ¬ åŒ…å«è§†é¢‘: {len(video_notes)} æ¡")
        print(f"   ğŸ­ å¤åˆå†…å®¹: {len(complex_notes)} æ¡")
        
        # åˆ†æ‰¹å¤„ç†å„ç±»å‹å†…å®¹
        total_processed = 0
        
        if text_only_notes:
            print(f"\nğŸ”„ å¤„ç†çº¯æ–‡æœ¬å†…å®¹...")
            processed = self._process_batch(text_only_notes, "çº¯æ–‡æœ¬")
            total_processed += processed
        
        if image_notes:
            print(f"\nğŸ”„ å¤„ç†å›¾ç‰‡å†…å®¹...")
            processed = self._process_batch(image_notes, "å›¾ç‰‡")
            total_processed += processed
            
        if video_notes:
            print(f"\nğŸ”„ å¤„ç†è§†é¢‘å†…å®¹...")
            processed = self._process_batch(video_notes, "è§†é¢‘")
            total_processed += processed
            
        if complex_notes:
            print(f"\nğŸ”„ å¤„ç†å¤åˆå†…å®¹...")
            processed = self._process_batch(complex_notes, "å¤åˆ")
            total_processed += processed
        
        print(f"\nâœ… æ€»è®¡å¤„ç†å®Œæˆ: {total_processed} æ¡è®°å½•")
    
    def _process_batch(self, notes: list, content_type: str) -> int:
        """å¤„ç†å•ä¸ªæ‰¹æ¬¡"""
        if not notes:
            return 0
            
        print(f"   ğŸ“‹ å¼€å§‹å¤„ç† {len(notes)} æ¡{content_type}å†…å®¹...")
        
        successful_results = []
        failed_count = 0
        
        for i, note in enumerate(notes):
            try:
                # ä½¿ç”¨å¤šæ¨¡æ€åˆ†æå™¨å¤„ç†
                result = self.analyzer._run(json.dumps(note, ensure_ascii=False))
                parsed_result = json.loads(result)
                
                # æ£€æŸ¥æ˜¯å¦åˆ†ææˆåŠŸ
                if parsed_result.get('_analysis_failed', False):
                    failed_count += 1
                    print(f"      âš ï¸ ç¬¬{i+1}æ¡åˆ†æå¤±è´¥: {parsed_result.get('_error_message', 'Unknown')}")
                else:
                    # æ·»åŠ åŸå§‹æ•°æ®IDç­‰ä¿¡æ¯
                    if 'id' in note:
                        parsed_result['id'] = note['id']
                    successful_results.append(parsed_result)
                    
            except Exception as e:
                failed_count += 1
                print(f"      âŒ ç¬¬{i+1}æ¡å¤„ç†å¼‚å¸¸: {e}")
        
        # æ‰¹é‡å†™å…¥æˆåŠŸçš„ç»“æœ
        if successful_results:
            try:
                write_result = self.db_writer._run(json.dumps(successful_results, ensure_ascii=False))
                if "æˆåŠŸå†™å…¥" in write_result:
                    written_count = len(successful_results)
                    print(f"   âœ… {content_type}å†…å®¹å¤„ç†å®Œæˆ: æˆåŠŸ {written_count} æ¡ï¼Œå¤±è´¥ {failed_count} æ¡")
                    return written_count
                else:
                    print(f"   âŒ {content_type}å†…å®¹æ•°æ®åº“å†™å…¥å¤±è´¥")
                    return 0
            except Exception as e:
                print(f"   âŒ {content_type}å†…å®¹å†™å…¥å¼‚å¸¸: {e}")
                return 0
        else:
            print(f"   âš ï¸ {content_type}å†…å®¹ï¼šæ— æˆåŠŸç»“æœå¯å†™å…¥")
            return 0
    
    def get_multimodal_statistics(self):
        """è·å–å¤šæ¨¡æ€æ•°æ®ç»Ÿè®¡"""
        print("ğŸ“Š å¤šæ¨¡æ€æ•°æ®ç»Ÿè®¡åˆ†æ...")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ ä»æ•°æ®åº“è·å–ç»Ÿè®¡ä¿¡æ¯çš„é€»è¾‘
        # ä¾‹å¦‚ï¼šå›¾ç‰‡æ•°é‡åˆ†å¸ƒã€è§†é¢‘æ•°é‡åˆ†å¸ƒç­‰
        pass

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¤šæ¨¡æ€æ•°æ®æ‰¹å¤„ç†å™¨å¯åŠ¨")
    print("="*60)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    required_env_vars = ['SEO_SUPABASE_URL', 'SEO_SUPABASE_ANON_KEY', 'OPENROUTER_API_KEY']
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]
    
    if missing_vars:
        print(f"âŒ ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")
        return
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = MultimodalBatchProcessor()
    
    # æ£€æŸ¥å¤šæ¨¡æ€åˆ†æå™¨åˆå§‹åŒ–
    if not processor.analyzer.client:
        print("âŒ å¤šæ¨¡æ€åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIé…ç½®")
        return
    
    print("âœ… åˆå§‹åŒ–å®Œæˆï¼Œå¼€å§‹å¤„ç†...")
    print("="*60)
    
    # å¤„ç†å¤šæ¨¡æ€æ•°æ®
    batch_size = 100  # å¯æ ¹æ®éœ€è¦è°ƒæ•´
    success = processor.process_multimodal_data(batch_size)
    
    if success:
        print("\n" + "="*60)
        print("ğŸ‰ å¤šæ¨¡æ€æ•°æ®æ‰¹å¤„ç†å®Œæˆï¼")
        print(f"â° å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    else:
        print("\n" + "="*60)
        print("âŒ å¤šæ¨¡æ€æ•°æ®æ‰¹å¤„ç†å¤±è´¥")

if __name__ == "__main__":
    main() 